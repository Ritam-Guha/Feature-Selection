# -*- coding: utf-8 -*-
"""select_feature.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FKdZsITaTxktmdJyozU_J5oGl3MPXo0Q
"""
#feature selection package:
#http://featureselection.asu.edu/html/skfeature.function.html

from sklearn import metrics
from scipy.stats.stats import pearsonr
from scipy.stats.stats import spearmanr
from scipy.stats.stats import ttest_ind
from scipy.stats.stats import kendalltau
import scipy.io
import pandas, numpy as np
import sys
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier as rf
from sklearn.neighbors import KNeighborsClassifier as knn
from skfeature.function.statistical_based import gini_index
from prettytable import PrettyTable
from ReliefF import ReliefF as rlf
from tabulate import tabulate

def genAcc(train,trainLabel,test,testLabel,features):
	clf=rf(n_estimators=100)
	train=train[:,features]
	test=test[:,features]
	clf.fit(train,trainLabel)
	val=clf.score(test,testLabel)
	return val

def normalize(vec):
  minimum=min(vec)
  maximum=max(vec)
  normVec=np.ones(len(vec))
  if maximum==minimum:
    return normVec
  normVec=(vec-minimum)/(maximum-minimum)
  return normVec

def ttest_f(train,trainLabel,loop):
	(a,b)=np.shape(train)
	score=np.zeros(b)
	target=trainLabel
	for i in range(b):
		fea=train[:,i]
		val=ttest_ind(fea,target)[0]
		score[i]=val
	ranking=np.argsort(score)[::-1]
	return ranking[0:loop]


datasetNames=['ILBPnew05-10-17','LBPnew05-10-17','RULBP35','RULBP45','RULBP55','RULBP_op15','RULBP_op100','RULBP_op110']

# for datasetName in datasetNames:
def main(datasetName):
	# datasetName='LBP variants/RULBP5'
	print('Dataset-',datasetName)
	data=pandas.read_csv('Data/'+datasetName+'.csv')
	(rows,cols)= np.shape(data)
	print ('numRows: ',rows), print ("numCols: ",cols)
	target=data.values[:,cols-1]
	datanew=data.values[:,0:cols-1]
	train, test, trainLabel, testLabel = train_test_split(datanew, target,stratify=target ,test_size=0.2)
	(rows1,cols1)= np.shape(train)
	(rows2,cols2)= np.shape(test)
	cols=cols1

	# train = trainData.values[:,0:cols-1]
	# trainLabel = trainData.values[:,cols-1]
	# test=testData.values[:,0:cols-1]
	# testLabel = testData.values[:,cols-1]

	print ('numTrainRows: ',rows1), print ("numTrainCols: ",cols1)
	print ('numTestRows: ',rows2), print ("numTestCols: ",cols2)
	numFeatures=cols-1

	# PccScore calculation
	PccScore=np.zeros(numFeatures)
	for loop1 in range(numFeatures):
	  curFeature=train[:,loop1]  
	  curVal=0.0
	  for loop2 in range(numFeatures):
	    if loop1!=loop2:
		    corrFeature=train[:,loop2]
		    PccScore[loop1]+=pearsonr(curFeature,corrFeature)[0]    
	PccScore=normalize(PccScore)

	print('PCC calculation done..')
	#MiScore calculation
	MiScore=np.zeros(numFeatures)

	for loop in range(numFeatures):
	  curFeature=train[:,loop]
	  MiScore[loop]=metrics.mutual_info_score(curFeature,trainLabel)   
	MiScore=normalize(MiScore)
	print('MI calculation done..')

	#combScore calculation
	impClass=0.8
	impFeature=1-impClass
	combScore=np.zeros(numFeatures)
	for loop in range(numFeatures): 
	  combScore[loop]=impClass*MiScore[loop] + impFeature*(-PccScore[loop])
	  # combScore[loop]=MiScore[loop]-PccScore[loop]
	print('Combo calculation done..')

	sortedFeaturesMi=np.argsort(-MiScore)
	sortedFeaturesPcc=np.argsort(PccScore)
	sortedFeaturesComb=np.argsort(-combScore)

	table2=PrettyTable(['NumFeat','comb','Mi','Pcc','ReliefF','Ttest','GI','MAX'])
	f=open('Results/Results_'+datasetName,'w+')
	f.write('%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n' % ('NumFeat','comb','Mi','Pcc','ReliefF','Ttest','GI','MAX'))

	for loop in range(20,cols-1,20):
		f=open('Results/Results_'+datasetName,'a+')
		maxVal=0;
		maxMethod='None'

		#chi2
		# chi2_features = SelectKBest(chi2, k = loop) 
		# chi2Train = chi2_features.fit_transform(train,trainLabel)
		# chi2Test = chi2_features.transform(test)
		# clf=rf(n_estimators=100)
		# clf.fit(chi2Train,trainLabel)
		# accChi2=clf.score(chi2Test,testLabel)	


		#ttest
		tt_features=ttest_f(train,trainLabel,loop)		
		temp=tt_features
		newTrain=train[:,temp]
		newTest=test[:,temp]
		clf.fit(newTrain,trainLabel)
		accTtest=clf.score(newTest,testLabel)	
		if maxVal<accTtest:
			maxVal=accTtest
			maxMethod='Ttest'

		#gini index
		score= gini_index.gini_index(train , trainLabel )
		ranking =np.argsort(score)[::-1]
		temp=ranking[0:loop]
		newTrain=train[:,temp]
		newTest=test[:,temp]
		clf.fit(newTrain,trainLabel)
		accGini=clf.score(newTest,testLabel)			
		if maxVal<accTGini:
			maxVal=accGini
			maxMethod='GI'

		#calculate relieff
		fsRlf=rlf(n_features_to_keep=loop)
		rlfTrain=fsRlf.fit_transform(train,trainLabel)	
		rlfTest=fsRlf.transform(test)
		clf=rf(n_estimators=100)
		clf.fit(rlfTrain,trainLabel)
		accRlf=clf.score(rlfTest,testLabel)	
		if maxVal<accRlf:
			maxVal=accRlf
			maxMethod='ReliefF'
		accComb=genAcc(train,trainLabel,test,testLabel,sortedFeaturesComb[0:loop])
		if maxVal<accComb:
			maxVal=accComb
			maxMethod='comb'
		accMi=genAcc(train,trainLabel,test,testLabel,sortedFeaturesMi[0:loop])
		if maxVal<accMi:
			maxVal=accMi
			maxMethod='Mi'
		accPcc=genAcc(train,trainLabel,test,testLabel,sortedFeaturesPcc[0:loop])
		if maxVal<accPcc:
			maxVal=accPcc
			maxMethod='Pcc'
		table2.add_row([loop,accComb,accMi,accPcc,accRlf,accTtest,accGini,maxMethod])
		print(table2)
		f.write('%d\t%4.2f\t%4.2f\t%4.2f\t%4.2f\t%4.2f\t%4.2f\t%s\n' % (loop,accComb*100,accMi*100,accPcc*100,accRlf*100,accTtets*100,accGini*100,maxMethod))
	
	f.close()

if __name__=="__main__":
	for loop in datasetNames:
		main('LBP variants/'+loop)
